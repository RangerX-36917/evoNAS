\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=0.75in]{geometry}
\usepackage{booktabs}
\usepackage{listing}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{array}
\usepackage{url}
\usepackage{cite}
\usepackage{complexity}
\usepackage{algpseudocode}
 \usepackage{graphicx}
 \usepackage{enumerate}
 \usepackage{subcaption}
 \usepackage[shortlabels]{enumitem}

\begin{document}
	\begin{center}
    
    	% MAKE SURE YOU TAKE OUT THE SQUARE BRACKETS
    
		\LARGE{\textbf{Bloodline Preserving Evolutionary Neural Architecture Search for Image Classification}} \\
        \vspace{1em}
        \Large{Project Proposal} \\
        \vspace{1em}
        \normalsize\textbf{ Bowen Zheng   }  
        \normalsize\textbf{ Shijie Chen   } 
        \normalsize\textbf{ Shuxin Wang  } 
        
        \vspace{1em}
        \normalsize{Advisor: Hisao Ishibuchi} \\
        \vspace{1em}
        \normalsize{Southern University of Science and Technology} 
	\end{center}
    \begin{normalsize}
    
    	
      
		\section{Background \& Rationale}
        
      The great leap of computing resources in the past few decades made it possible to fully utilize the potential of neural networks. In recent years neural networks outperformed traditional methods in many fields of research, especially image classification. However, the state-of-the-art architectures are carefully designed and tuned by researchers for a specific problem. Therefore, people start to think about automate the design of neural networks in the hope of finding the best-performing network architecture efficiently.

      Neural architecture search is a research field focusing on automating the design of neural networks. Currently there are a few popular approaches, including reinforcement learning, bayesian optimization, tree-based searching and genetic-based evolutionary algorithms. 

      This project focuses on NAS for image classification problems. The reason is that this area is well explored and there exists many high-performance hand-crafted neural architectures. They provide a good guidance and target to our project. In addition, neural networks for image classification are mostly built upon basic cells including convolution, polling, normalization, and activation layers. This helps to shrink our search space.
    
    \section{Problem Definition}
      Neural Architecture Search (NAS) refers to the process of automatically designing artificial neural network architectures \cite{elsken2018neural}. Research topics in NAS are generally categorized into three categories:
      \begin{enumerate}
        \item \textbf{\emph{Search Space}}
         The search space of NAS denotes the space in which the NAS algorithm tries to find a neural network architecture.
        \item \textbf{\emph{Search Strategy}} The search strategy of NAS denotes the search algorithm that is used to explore the \emph{search space}.
        \item \textbf{\emph{Performance Estimation Strategy}} NAS algorithms will generate a large quantity of neural network architectures during search process. We need an efficient way to estimate the performance of each architecture to cut the demand for computational resource. 
      \end{enumerate}

   
    \section{Objective}

    The objective of this project is to propose a novel evolutionary approach for neural architecture search targeted at image classification. The specific objectives are as follows:
    \begin{enumerate}
      \item Investigate existing evolutionary neural architecture search algorithms.
      \item Find an efficient estimate approximation of neural networks to cut computational cost.
      \item Propose an effective population selection strategy.
      \item Compare performance against hand-crafted networks as well as other NAS algorithms.
    \end{enumerate}

    \section{Related Works}
    A lot of research works have been done in each of the three categories in NAS. Some proposed algorithms can design architectures that is on par of or even more capable than state-of-the-art hand-crafted networks.
    
    \subsection{Search Space}
    
    The search space of NAS determines the possible architectures a NAS algorithm can find.

    The simplest search space is the simple multiple-layer structure, in which a neural network $A$ is composed of multiple layers $L_i$ connected to the neighboring layers. In this case, the search space can be described by (1) The maximum number of layers (2) The type and dimension of each layer and their hyper-parameters\cite{chollet2017xception}\cite{baker2016designing}. 

    In more recent studies, some researchers use a cell based search space in which the possible architecture of cells are explored. A cell is nothing but a smaller neural network. The entire neural network is constructed by connecting several pre-defined cells. A cell has less layers but allows more complex architectures like skip connections between any layers\cite{cai2018path}\cite{real2018regularized}. The cell could be some hand-crafted neural networks that have already been proofed effective. The search space is therefore decreased to the possible arrangements of cells.

    In contrast to the above direction, some researchers also tried to search for effective cells and connect them at last in a predefined manner\cite{zoph2018learning}\cite{cai2018path}. The search space is greatly decreased in that each cell is comparably small. This method can also be easily transferred to other datasets\cite{zoph2018learning} since the structure of cells are not fixed.

    Recently, some researchers managed to optimize the overall architecture as well as the cells at the same time and obtained state-of-the-art result\cite{liu2019auto}.
    
    \subsection{Search Strategy}
    
    Many different search strategies can be applied to explore the search space discussed above. These methods includes bayesian optimization, evolutionary methods, reinforcement learning and gradient-based methods. 

    Evolutionary algorithms has been used to evolve neural networks since 1989\cite{miller1989designing}. Earlier works use genetic algorithms to both optimize the structure of neural networks and train the networks\cite{stanley2002evolving}. However, with the birth of back-propagation (BP), recent works of neural-evolution use genetic algorithms only for optimizing neural architectures and use BP to train the networks\cite{real2017large}. In the context of NAS, the individuals in the genetic algorithm are neural network architectures and the genetic operations (crossover and mutation) are used to alter the architecture by adding/removing layers or change connectivity of nodes.

    Genetic algorithms shows their diversity in how they sample parents, generate offspring and update population. Some work choose parents from a preto-optimal front\cite{elsken2018efficient} while others use tournament selection\cite{liu2018progressive}\cite{real2018regularized}\cite{real2017large}. When generating offsprings, some algorithms randomly initialize weight of child networks. In comparison, Lamarckian inheritance is used in \cite{elsken2018efficient} so that child networks could inherit weight of its parent and the training cost is reduced. To update population, some algorithms abandon least capable individuals\cite{real2017large} while some delete the oldest individuals\cite{real2018regularized}. A more sophisticated policy is developed by \cite{Hornby:2006:AAP:1143997.1144142} and \cite{DBLP:journals/corr/abs-1802-01548} in which the age of the individuals are taken into account.
    
    There are other methods that are used to implement NAS, including bayesian optimization, reinforcement learning ,tree-based search and gradient-based methods. We don't discuss them here since we use evolutionary algorithms in our project.

    \subsection{Performance Estimation Strategy}
    One important issue in neural architecture search is the estimation of neural network performance. This is critical in the population update policy of evolutionary algorithms. 

    The simplest way to estimate performance is to train every searched network from scratch and test the desired performance metric, e.g. accuracy on validation set. However, the training of neural network is very time and computation consuming. 
    
    An alternative is to estimate performance on lower fidelities. More specifically, to train the network for shorter period of time\cite{zoph2018learning} or on some subset of the dataset\cite{klein2016fast}. However, the estimate must ensure the result ranking of different networks must be the same as that of complete training. That is to say, there exist a trade-off between computational load and estimation fidelity.

    Another approach to estimate performance is based on learning curve extrapolation\cite{domhan2015speeding}. This method accelerate estimation by stop poor performance networks at the early state of training based on statistical patterns of learning curves. Other researchers propose ways to predict neural network performance based on architectural and cell properties\cite{liu2018progressive}. 

    \section{Methodology}

    We will develop an evolutionary neural architecture search algorithm based on the $age$ of individuals. By incorporating $age$ as a part of gene, we can prolong the existence of good individuals\cite{DBLP:journals/corr/abs-1802-01548} and kill average individuals when their age reach a certain limit\cite{Hornby:2006:AAP:1143997.1144142}. 

    Combining the advantage of the above works, we propose a population update police based on $age$ and $bloodline$. An individual is dropped from the total population if its $age$ exceeds a predefined $lifetime$. However, we prolong its life if its offspring performs well (e.g. within top $P\%$ in ranking). In this way, we can preserve a good $bloodline$ in the population.

    To test the effectiveness of our algorithm, we will experiment on image classification datasets including CIFAR-10, CIFAR-100 and will possibly extend to IMAGENET.


  \section{System Design}

  \begin{algorithm}[htb]  
    \caption{ Aging Bloodlines Evolution:}
    \begin{algorithmic}[1]  
  
    \State $population\gets \phi$
    \State $entireGen\gets \phi$
    \State $generation\gets 0$
    
    \While{$population$ size$<N$}
    \State $newNetwork\gets networkInit()$
    \State $trainNetwork(newNetwork)$
    \State add $newNetwork$ to $popution$ and $entireGen$
    \EndWhile
    
  
    
    \While {$genetation < G$}
      \State $parent\gets$ select a parent from population using tournament selection 
      \State $child \gets mutate(parent)$
      \State $trainNetwork(child)$
      \State add $child$ to $popution$ and $entireGen$
      \If {accuracy of $child$ is better than $P\%$ individuals in population}
        \State extend the $lifetime$ of $parent$ by $t$
      \EndIf
      
      \ForAll {$individual$ in $population$}
        \State update the $age$ of $individual$
        \State remove current $individual$ if its age reaches its $lifetime$
      \EndFor
      
      
    \EndWhile
    
    
    \\  
    \Return the network model with highest accuracy in $entireGen$
 
  \end{algorithmic}  
  \end{algorithm}  


\end{normalsize}

The $population$ size is $N$ and we do $G$ times generations. $entireGen$ stores all network models that we generated. 
     
In $networkInit()$, the initial network model will be generated. Then its $age $ will be set to 1 and $lifetime$ will be set to default value. 

$P$ and $t$ are hyper-parameter that relate to the ultimate lifetime of individuals.

We will have a further discussion on how to initialize and do mutate on networks. We may follow \cite{DBLP:journals/corr/abs-1802-01548} to implement a cell based NAS at first. 


\bibliographystyle{ieeetr}
\bibliography{ref}

\end{document}